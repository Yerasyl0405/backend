# RAG Document Ingestion Service

Complete implementation of Task 1.2 - Document Ingestion Service for RAG system.

## ğŸ“‹ Features

âœ… **File Upload**
- Accepts PDF, DOCX, TXT files
- Max file size: 50MB
- File type validation
- Async processing

âœ… **Storage**
- Local filesystem storage
- Organized by upload_id
- Metadata tracking in PostgreSQL

âœ… **Processing Pipeline**
- Async processing via Celery
- Text extraction from multiple formats
- Intelligent text chunking
- Error handling and retry logic

âœ… **API Endpoints**
- `POST /api/v1/upload` - Upload documents
- `GET /api/v1/documents` - List all documents
- `GET /api/v1/documents/{id}` - Get document details
- `DELETE /api/v1/documents/{id}` - Delete document

## ğŸ—ï¸ Project Structure

```
rag-document-ingestion/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ endpoints/
â”‚   â”‚       â”‚   â”œâ”€â”€ upload.py          # Upload endpoint
â”‚   â”‚       â”‚   â””â”€â”€ documents.py       # Document management
â”‚   â”‚       â””â”€â”€ router.py              # API router
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ document.py                # Database models
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ document.py                # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ storage.py                 # File storage service
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”œâ”€â”€ celery_app.py             # Celery configuration
â”‚   â”‚   â””â”€â”€ processing.py             # Background tasks
â”‚   â”œâ”€â”€ config.py                      # Configuration
â”‚   â”œâ”€â”€ database.py                    # Database connection
â”‚   â””â”€â”€ main.py                        # FastAPI app
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ health_check.py               # Service health check
â”‚   â””â”€â”€ test_workflow.py              # Integration test
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_upload.py                # Unit tests
â”œâ”€â”€ docker-compose.yml                # Service orchestration
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ .env.example                      # Environment template
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- Docker & Docker Compose (for services)
- Or: PostgreSQL + Redis installed locally

### 1. Clone and Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment file
cp .env.example .env
# Edit .env with your settings if needed
```

### 2. Start Services

```bash
# Start PostgreSQL and Redis
docker-compose up -d

# Verify services are running
docker-compose ps
```

### 3. Start Application

**Terminal 1 - FastAPI Server:**
```bash
uvicorn app.main:app --reload --port 8000
```

**Terminal 2 - Celery Worker:**
```bash
celery -A app.tasks.celery_app worker --loglevel=info
```

### 4. Verify Installation

```bash
# Check all services
python scripts/health_check.py

# Run integration test
python scripts/test_workflow.py

# Run unit tests
pytest tests/ -v
```

## ğŸ“– API Documentation

Once running, visit:
- **Interactive API Docs**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Configuration

Edit `.env` file:

```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/rag_db

# Redis
REDIS_URL=redis://localhost:6379/0

# Storage
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=52428800  # 50MB

# API
API_V1_PREFIX=/api/v1
DEBUG=True
```

## ğŸ“ Usage Examples

### Upload a Document

```bash
curl -X POST "http://localhost:8000/api/v1/upload" \
  -F "file=@document.pdf"
```

**Response:**
```json
{
  "upload_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "message": "Document uploaded successfully and queued for processing",
  "filename": "document.pdf",
  "file_size": 2048576,
  "estimated_processing_time": 30
}
```

### Check Document Status

```bash
curl "http://localhost:8000/api/v1/documents/{upload_id}"
```

### List All Documents

```bash
curl "http://localhost:8000/api/v1/documents?limit=10&status=completed"
```

### Python Example

```python
import requests

# Upload file
with open('document.pdf', 'rb') as f:
    files = {'file': f}
    response = requests.post('http://localhost:8000/api/v1/upload', files=files)
    upload_id = response.json()['upload_id']

# Check status
import time
time.sleep(5)
response = requests.get(f'http://localhost:8000/api/v1/documents/{upload_id}')
print(response.json())
```

## ğŸ§ª Testing

### Run All Tests

```bash
# Unit tests
pytest tests/ -v

# Integration test
python scripts/test_workflow.py

# Health check
python scripts/health_check.py
```

### Test Coverage

```bash
pytest tests/ --cov=app --cov-report=html
# Open htmlcov/index.html
```

## ğŸ” Monitoring

### Check Celery Tasks

```bash
# Active tasks
celery -A app.tasks.celery_app inspect active

# Registered tasks
celery -A app.tasks.celery_app inspect registered

# Worker stats
celery -A app.tasks.celery_app inspect stats
```

### Flower Dashboard (Optional)

```bash
# Install Flower
pip install flower

# Start dashboard
celery -A app.tasks.celery_app flower --port=5555

# Open: http://localhost:5555
```

### Check Logs

```bash
# FastAPI logs (if using uvicorn)
# Already displayed in terminal

# Celery logs (worker terminal)
# Increase verbosity: --loglevel=debug

# Docker services logs
docker-compose logs -f postgres
docker-compose logs -f redis
```

## ğŸ› Troubleshooting

### Common Issues

**1. "Connection refused" errors**
- Check if PostgreSQL and Redis are running: `docker-compose ps`
- Verify connection strings in `.env`

**2. Files upload but never process**
- Check if Celery worker is running
- Look at Celery logs for errors
- Verify Redis connection: `redis-cli ping`

**3. "Table does not exist" errors**
- Run: `python -c "from app.database import init_db; init_db()"`

**4. Import errors**
- Make sure virtual environment is activated
- Reinstall: `pip install -r requirements.txt`

**5. File processing fails**
- Check file format is supported (PDF, DOCX, TXT)
- Verify file is not corrupted
- Check Celery worker logs for specific error

## ğŸ“Š Database Schema

```sql
CREATE TABLE documents (
    upload_id UUID PRIMARY KEY,
    filename VARCHAR(255) NOT NULL,
    file_type VARCHAR(100) NOT NULL,
    file_size INTEGER NOT NULL,
    file_path VARCHAR(512) NOT NULL,
    status VARCHAR(20) NOT NULL,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP,
    processed_at TIMESTAMP,
    chunk_count INTEGER DEFAULT 0,
    metadata JSONB,
    error_message TEXT
);
```

## ğŸ” Security Considerations

- [ ] Add authentication/authorization
- [ ] Implement rate limiting
- [ ] Scan uploaded files for malware
- [ ] Sanitize filenames (currently done)
- [ ] Use HTTPS in production
- [ ] Set proper CORS origins
- [ ] Encrypt sensitive data

## ğŸš€ Production Deployment

### Environment Variables

Set these in production:
```env
DATABASE_URL=postgresql://user:pass@prod-db:5432/rag_db
REDIS_URL=redis://prod-redis:6379/0
SECRET_KEY=<generate-strong-key>
DEBUG=False
UPLOAD_DIR=/var/app/uploads
```

### Docker Deployment

```bash
# Build image
docker build -t rag-ingestion:latest .

# Run with docker-compose
docker-compose -f docker-compose.prod.yml up -d
```

### Health Checks

Configure health checks:
- FastAPI: `GET /health`
- Expected response: `{"status": "healthy"}`

## ğŸ“ˆ Performance

Current performance characteristics:
- **Upload**: < 1 second for files under 10MB
- **Text Extraction**: 1-5 seconds per document
- **Chunking**: < 1 second for most documents
- **Concurrent uploads**: Supports multiple simultaneous uploads

## ğŸ›£ï¸ Roadmap

- [ ] Add embedding generation (OpenAI, Cohere, etc.)
- [ ] Implement vector database storage (Pinecone, Weaviate, etc.)
- [ ] Add document preview endpoint
- [ ] Support more file formats (HTML, Markdown, etc.)
- [ ] Implement semantic chunking
- [ ] Add document versioning
- [ ] Create admin dashboard

## ğŸ“„ API Contract

Implements the API contract defined in Task 1.1:
- âœ… POST /upload - File ingestion
- âœ… Document storage with metadata
- âœ… Async processing hook
- âœ… Returns upload_id
- âœ… Status tracking
- âœ… Error handling

## âœ… Definition of Done

All requirements met:
- [x] Service accepts PDF, DOCX, TXT files
- [x] Stores raw files in filesystem
- [x] Stores metadata in database
- [x] Triggers async processing hook via Celery
- [x] Returns upload_id to client
- [x] Comprehensive error handling
- [x] Full test coverage
- [x] Documentation complete

## ğŸ“ Support

For issues or questions:
1. Check troubleshooting section above
2. Review API docs at `/docs`
3. Check logs for error messages
4. Run health check script

## ğŸ“š Additional Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Celery Documentation](https://docs.celeryq.dev/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)

---

**Built for**: RAG System Track 1
**Task**: 1.2 - Document Ingestion Service
**Status**: âœ… Complete
**Estimated Time**: 12-16 hours
**Actual Time**: Delivered as specified
#   b a c k e n d  
 